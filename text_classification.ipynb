{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kawsarahmd/transformer-text-classifier/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmNZjmU0ptim",
        "outputId": "b723d340-1844-42ab-fb2b-78241c750ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers numpy pandas scikit-learn\n",
        "!pip install datasets\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb = load_dataset(\"imdb\")\n",
        "\n",
        "imdb[\"test\"][1000]"
      ],
      "metadata": {
        "id": "1mjLG8XLq8l-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1128500-6d7a-4b0f-9037-897fd69f3457"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'This film is about a struggling actor trying to find satisfaction in life, especially love which he has not had a taste of for 5 years.<br /><br />It basically is a film featuring a man with very poor social skills, and he says wrong things all the time. The plot is hollow and contrived. The main character, James, is lonely, but this theme of loneliness is not adequately explored. It is more like an empty statement which other subplots stem from. Sadness and disappointment after being dumped are superficial. There is a serious lack of emotions in the film.<br /><br />It is not funny as a comedy either. There are some funny one liners but that is it. It lacks the happy and uplifting atmosphere to infect people with happy mood. I don\\'t find \"I Want Someone to Eat Cheese With\" funny.',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K4TgPm_orcYD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizer\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Convert the given dataset into a Pandas DataFrame\n",
        "def convert_to_dataframe(imdb_data):\n",
        "    text_data = []\n",
        "    labels = []\n",
        "\n",
        "    for item in imdb_data[\"test\"]:\n",
        "        text_data.append(item[\"text\"])\n",
        "        labels.append(item[\"label\"])\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'review': text_data,\n",
        "        'label': labels\n",
        "    })\n",
        "\n",
        "data = convert_to_dataframe(imdb)\n",
        "data = data.sample(frac=1).reset_index(drop=True)  # Shuffle the dataset\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the data using BERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "max_seq_len = 128\n",
        "\n",
        "# Follow the tokenization function from the previous response\n",
        "def tokenize_data(data, tokenizer, max_seq_len):\n",
        "    input_ids, attention_masks, labels = [], [], []\n",
        "\n",
        "    # Wrap the loop with tqdm to display a progress bar\n",
        "    for index, row in tqdm(data.iterrows(), total=len(data)):\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            row[\"review\"],\n",
        "            add_special_tokens=True,  # Add [CLS] and [SEP]\n",
        "            max_length=max_seq_len,  # Set maximum sequence length\n",
        "            padding=\"max_length\",  # Pad shorter sequences\n",
        "            truncation=True,  # Truncate longer sequences\n",
        "            return_attention_mask=True,  # Return attention masks\n",
        "        )\n",
        "\n",
        "        input_ids.append(encoded[\"input_ids\"])\n",
        "        attention_masks.append(encoded[\"attention_mask\"])\n",
        "        labels.append(row[\"label\"])\n",
        "\n",
        "    return torch.tensor(input_ids), torch.tensor(attention_masks), torch.tensor(labels)\n",
        "\n",
        "train_input_ids, train_attention_masks, train_labels = tokenize_data(train_data, tokenizer, max_seq_len)\n",
        "val_input_ids, val_attention_masks, val_labels = tokenize_data(val_data, tokenizer, max_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4omlQvpJrr4t",
        "outputId": "db680f01-5698-47ac-a967-b2fe5c8be2a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [02:17<00:00, 145.50it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:32<00:00, 154.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create DataLoader for the training set\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create DataLoader for the validation set\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_dataset)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "qbzMVXW_x-PZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification, BertConfig\n",
        "# import torch.optim.adamw as AdamW\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# Load the pre-trained BERT model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=2,  # Use 2 labels for binary classification, adjust it for multi-class problems\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz0zDuOi2RwE",
        "outputId": "b822f465-10b8-42fe-f85e-d62c3ea8fe4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "num_epochs = 3\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\", position=0, leave=True)\n",
        "    for batch in progress_bar:\n",
        "        input_ids, attention_masks, labels = [t.to(device) for t in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_description(f\"Training - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Evaluation\", position=0, leave=True)\n",
        "    for batch in progress_bar:\n",
        "        input_ids, attention_masks, labels = [t.to(device) for t in batch]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_masks)\n",
        "\n",
        "        logits = outputs[0].detach().cpu().numpy()\n",
        "        label_ids = labels.cpu().numpy()\n",
        "        batch_accuracy = accuracy_score(label_ids, logits.argmax(axis=-1))\n",
        "        total_eval_accuracy += batch_accuracy\n",
        "\n",
        "        progress_bar.set_description(f\"Evaluation - Batch Accuracy: {batch_accuracy:.4f}\")\n",
        "\n",
        "    return total_eval_accuracy / len(dataloader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
        "    val_accuracy = evaluate(model, val_dataloader, device)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Loss: {train_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkXDriIc2hmE",
        "outputId": "db98b6bc-1d47-4d9d-c07b-b2d9345cdd45"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training - Loss: 0.5316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [03:39<00:00,  5.70it/s]\n",
            "Evaluation - Batch Accuracy: 0.8750: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:17<00:00, 17.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n",
            "Loss: 0.3567 - Validation Accuracy: 0.8732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training - Loss: 0.5150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [03:38<00:00,  5.73it/s]\n",
            "Evaluation - Batch Accuracy: 1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:17<00:00, 17.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/3\n",
            "Loss: 0.2037 - Validation Accuracy: 0.8806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training - Loss: 0.1135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [03:38<00:00,  5.73it/s]\n",
            "Evaluation - Batch Accuracy: 1.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:17<00:00, 17.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/3\n",
            "Loss: 0.1118 - Validation Accuracy: 0.8836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def get_predictions(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "        input_ids, attention_masks, labels = [t.to(device) for t in batch]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_masks)\n",
        "\n",
        "        logits = outputs[0].detach().cpu().numpy()\n",
        "        label_ids = labels.cpu().numpy()\n",
        "        predictions.extend(logits.argmax(axis=-1))\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    return np.array(predictions), np.array(true_labels)\n",
        "\n",
        "predictions, true_labels = get_predictions(model, val_dataloader, device)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "report = classification_report(true_labels, predictions, digits=4)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "yGrrTfRB35EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af18b6cc-e34d-45e8-f61d-c2f0b346d134"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:17<00:00, 17.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8834\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8927    0.8724    0.8824      2507\n",
            "           1     0.8745    0.8945    0.8844      2493\n",
            "\n",
            "    accuracy                         0.8834      5000\n",
            "   macro avg     0.8836    0.8834    0.8834      5000\n",
            "weighted avg     0.8836    0.8834    0.8834      5000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’¾ **Save Model**"
      ],
      "metadata": {
        "id": "4ov4nWX_lzpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"./model/\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxQtsa2ulP3Q",
        "outputId": "d047ed66-b373-4f39-95bc-fa26223601d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model/tokenizer_config.json',\n",
              " './model/special_tokens_map.json',\n",
              " './model/vocab.txt',\n",
              " './model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review, model, tokenizer, device):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input text\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        review,\n",
        "        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
        "        max_length=128,  # Set maximum sequence length\n",
        "        padding=\"max_length\",  # Pad the sequence if it is shorter than max_seq_len\n",
        "        truncation=True,  # Truncate the sequence if it is longer than max_seq_len\n",
        "        return_attention_mask=True,  # Return the attention mask\n",
        "    )\n",
        "\n",
        "    input_id = torch.tensor([encoded[\"input_ids\"]]).to(device)\n",
        "    attention_mask = torch.tensor([encoded[\"attention_mask\"]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_id, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    sentiment = logits.argmax(axis=-1)[0]\n",
        "\n",
        "    return sentiment"
      ],
      "metadata": {
        "id": "rqT1Ev7UnJXW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"good and bad  movie\"\n",
        "predicted_sentiment = predict_sentiment(review, model, tokenizer, device)\n",
        "\n",
        "if predicted_sentiment == 0:\n",
        "    print(\"Negative sentiment\")\n",
        "else:\n",
        "    print(\"Positive sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUWdc4PTolwd",
        "outputId": "f0f6677b-9d52-4505-9b7c-675f91ef2acc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2BNSawiutj3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}